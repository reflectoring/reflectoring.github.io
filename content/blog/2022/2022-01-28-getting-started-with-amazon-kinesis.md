---
authors: [pratikdas]
title: "Getting Started with AWS Kinesis"
categories: ["aws"]
date: 2022-01-20T00:00:00
excerpt: "Amazon Simple Queue Service (SQS) is a fully managed message queuing service. We can send, store, and receive messages at any volume, without losing messages or requiring other systems to be available. In this article, we will introduce Amazon SQS, understand its core concepts and work through some examples."
image: images/stock/0115-2021-1200x628-branded.jpg
url: getting-started-with-aws-sqs
---

Amazon Kinesis is a fully managed service for real-time processing of streaming data at any scale.  Amazon Kinesis can collect and process hundreds of terabytes of data per hour from hundreds of thousands of sources, allowing you to easily write applications that process information in real-time, from sources such as web site click-streams, marketing and financial information, manufacturing instrumentation and social media, and operational logs and metering data. 

Being fully managed, Amazon SQS also eliminates the additional overhead associated with managing and operating message-oriented middleware thereby empowering developers to focus on application development instead of managing infrastructure. 

In this article, we will introduce Amazon Kinesis, understand its core concepts of the creating data streams, sending, and receiving data from streams and deriving analytical insights using different service variants: Kinesis Data Stream, firehose, Analytics, and Video Streams.

{{% github "https://github.com/thombergs/code-examples/tree/master/aws/kinesis" %}}

## What is Streaming Data

Streaming data is generated continuously (in a stream) by multiple data sources, which typically send in the data records simultaneously, and in small batches of size in the order of Kilobytes. 

Streaming data includes a wide variety of data such as log files generated by customers using mobile or web applications, ecommerce purchases, in-game player activity, information from social networks, financial trading floors, or geospatial services, and telemetry from connected devices or instrumentation in data centers.

Streaming data is processed sequentially and incrementally on a record-by-record basis or in batches aggregated over sliding time windows, and used for a wide variety of analytics including correlations, aggregations, filtering, and sampling.

## What is Amazon Kinesis
Amazon Kinesis is a fully managed streaming data platform for processing streaming data. It helps us to set up streams where producers can pump in data and receivers can consume data. Kinesis provides four specialized variants of services based on the type of stream processing we want to perform to suit our use case:

- **Kinesis Data Streams** : Amazon Kinesis Data Streams is a serverless streaming data service that 
we can use to build custom applications to process or analyze streaming data for specialized needs. We can add various types of data such as clickstreams, application logs, and social media to a Kinesis data stream from hundreds of thousands of sources.

- **Kinesis Data Firehose** : With Kinesis Data Firehose, we don't need to write applications or manage resources. We configure data producers to send data to Kinesis Data Firehose, and it automatically delivers the data to the specified destination. We can also configure Kinesis Data Firehose to transform the data before delivering it.

- **Kinesis Data Analytics**:With Amazon Kinesis Data Analytics for SQL Applications, you can process and analyze streaming data using standard SQL. The service enables you to quickly author and run powerful SQL code against streaming sources to perform time series analytics, feed real-time dashboards, and create real-time metrics.

- **Kinesis Video Streams**: Amazon Kinesis Video Streams is a fully managed AWS service that you can use to stream live video from devices to the AWS Cloud, or build applications for real-time video processing or batch-oriented video analytics.

Let us understand these services in the next sections. In each section is we will first introduce the key concepts of the service and then work through some examples.

## Kinesis Data Streams

Kinesis Data Streams helps us to set up streams and write producer and consumer applications.

### Key Concepts

A Kinesis data stream is a set of shards. Each shard has a sequence of data records. Each data record has a sequence number that is assigned by Kinesis Data Streams.

Stream: A stream is where we write our data also called data ingestion.

Shard: Each stream is divided into multiple shards. Shard is the data container.

Partition Key: Identifier of the shard where we want to send our data.

Record: The unit of data. Multiple records form the shard.

### Creating a Kinesis Data Stream


### Data Ingestion - Writing data to Kinesis Data Streams with KPL

We can add data to a Kinesis data stream through PutRecord and PutRecords operations, Amazon Kinesis Producer Library (KPL), or Amazon Kinesis Agent.

Amazon Kinesis Producer Library (KPL) is an easy-to-use and highly configurable library that helps you put data into an Amazon Kinesis data stream.It simplifies producer application development, allowing developers to achieve high write throughput to a Kinesis data stream.



## Kinesis Data Firehose
Amazon Kinesis Data Firehose is an extract, transform, and load (ETL) service that reliably captures, transforms, and delivers streaming data to data lakes, data stores, and analytics services.

Amazon Kinesis Data Firehose is a fully managed service for delivering real-time streaming data to destinations such as Amazon Simple Storage Service (Amazon S3), Amazon Redshift, Amazon OpenSearch Service, Splunk, and any custom HTTP endpoint or HTTP endpoints owned by supported third-party service providers, including Datadog, Dynatrace, LogicMonitor, MongoDB, New Relic, and Sumo Logic.

We don't need to write applications or manage resources. We configure your data producers to send data to Kinesis Data Firehose, and it automatically delivers the data to the destination that you specified. You can also configure Kinesis Data Firehose to transform your data before delivering it.

### Key Concepts

Kinesis Data Firehose delivery stream: We use Kinesis Data Firehose by creating a Kinesis Data Firehose delivery stream and then sending data to it. 

Record: The data of interest that your data producer sends to a Kinesis Data Firehose delivery stream. A record can be as large as 1,000 KB.

Data producer: Producers send records to Kinesis Data Firehose delivery streams. For example, a web server that sends log data to a delivery stream is a data producer. You can also configure your Kinesis Data Firehose delivery stream to automatically read data from an existing Kinesis data stream, and load it into destinations. 

Buffer size and buffer interval: Kinesis Data Firehose buffers incoming streaming data to a certain size or for a certain period of time before delivering it to destinations. Buffer Size is in MBs and Buffer Interval is in seconds.

### Creating a Delivery Stream

We can create a Kinesis Data Firehose delivery stream using the AWS Management Console or an AWS SDK.
Choose source and destination

### Sending Data to a Delivery Stream using Kinesis Data Streams


### Sending Data to a Delivery Stream using AWS SDK

### Sending Data to a Delivery Stream using Firehose Agent

### Data Transformation

Kinesis Data Firehose can invoke your Lambda function to transform incoming source data and deliver the transformed data to destinations. You can enable Kinesis Data Firehose data transformation when you create your delivery stream.

### Dynamic Partitioning


## Amazon Kinesis Data Analytics
Amazon Kinesis Data Analytics is the easiest way to analyze streaming data in real time. Using templates and built-in operators, you can quickly and easily build queries and stream real-time applications. Amazon Kinesis Data Analytics sets up the resources to run your applications and scales automatically to handle any volume of incoming data.

### Key Concepts
A Kinesis Data Analytics application has the following components:

Runtime properties: You can use runtime properties to configure your application without recompiling your application code.
Source: The application consumes data by using a source. A source connector reads data from a Kinesis data stream, an Amazon S3 bucket, etc. For more information, see Sources.
Operators: The application processes data by using one or more operators. An operator can transform, enrich, or aggregate data. For more information, see DataStream API Operators.
Sink: The application produces data to external sources by using sinks. A sink connector writes data to a Kinesis data stream, a Kinesis Data Firehose delivery stream, an Amazon S3 bucket, etc. For more information, see Sinks.

### Creating a Streaming Application

## Amazon Kinesis Video Streams
Amazon Kinesis Video Streams is a fully managed AWS service that you can use to stream live video from devices to the AWS Cloud, or build applications for real-time video processing or batch-oriented video analytics.

### Key Concepts

Producer – Any source that puts data into a Kinesis video stream. A producer can be any video-generating device, such as a security camera, a body-worn camera, a smartphone camera, or a dashboard camera. A producer can also send non-video data, such as audio feeds, images, or RADAR data.

Kinesis video stream – A resource that enables you to transport live video data, optionally store it, and make the data available for consumption both in real time and on a batch or ad hoc basis.

Consumer – Gets data, such as fragments and frames, from a Kinesis video stream to view, process, or analyze it. Generally these consumers are called Kinesis Video Streams applications.

### Creating a Kinesis Video Stream


### Sending Data to a Kinesis Video Stream


### Consuming Media Data
We can consume media data by either viewing it in the console, or by creating an application that reads media data from a stream using HLS.



Message Queueing is an asynchronous style of communication between two or more processes.

Messages and queues are the basic components of a message queuing system.

Programs communicate with each other by sending data in the form of messages which are placed in a storage called a queue, instead of calling each other directly. The receiver programs retrieve the message from the queue and do the processing without any knowledge of the producer programs.

This allows the communicating programs to run independently of each other, at different speeds and times, in different processes, and without having a direct connection between them.





## Conclusion

Here is a list of the major points for a quick reference:


You can refer to all the source code used in the article on [Github](https://github.com/thombergs/code-examples/tree/master/aws/sqs).

